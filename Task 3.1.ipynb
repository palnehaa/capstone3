{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3.1 - Data Analysis using Big Data Tools \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Develop a PySpark application to load data Spark DataFrames and save it into Hive tables on a Hadoop cluster in an optimized format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init('/usr/local/spark')\n",
    "import pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"Data Analysis using big Data Tools\") \\\n",
    "        .config(\"spark.sql.warehouse.dir\", \"hdfs://localhost:54310/user/hive/warehouse\") \\\n",
    "        .enableHiveSupport() \\\n",
    "        .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the data into pyspark dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF1=spark.read.load('/home/hduser/Downloads/sharedfolder/hr_Hiring_details.csv', format='csv', sep=',',inferSchema='true',header='true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Candidate Ref: integer (nullable = true)\n",
      " |-- DOJ Extended: string (nullable = true)\n",
      " |-- Duration to accept offer: integer (nullable = true)\n",
      " |-- Notice period: integer (nullable = true)\n",
      " |-- Offered band: string (nullable = true)\n",
      " |-- Pecent hike expected in CTC: double (nullable = true)\n",
      " |-- Percent hike offered in CTC: double (nullable = true)\n",
      " |-- Percent difference CTC: double (nullable = true)\n",
      " |-- Joining Bonus: string (nullable = true)\n",
      " |-- Candidate relocate actual: string (nullable = true)\n",
      " |-- Gender: string (nullable = true)\n",
      " |-- Candidate Source: string (nullable = true)\n",
      " |-- Rex in Yrs: integer (nullable = true)\n",
      " |-- Location: string (nullable = true)\n",
      " |-- Age: integer (nullable = true)\n",
      " |-- LOB_id: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "DF1.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Renaming the columns for storing in the tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "hr_hiring = DF1.withColumnRenamed(\"Candidate Ref\",\"Candidate_Ref\") \\\n",
    "        .withColumnRenamed(\"DOJ Extended\",\"DOJ_Extended\") \\\n",
    "        .withColumnRenamed(\"Duration to accept offer\",\"Duration_to_accept_offer\") \\\n",
    "        .withColumnRenamed(\"Notice period\",\"Notice_period\") \\\n",
    "        .withColumnRenamed(\"Offered band\",\"Offered_band\") \\\n",
    "        .withColumnRenamed(\"Pecent hike expected in CTC\",\"Percent_hike_offered_in_CTC\") \\\n",
    "        .withColumnRenamed(\"Percent hike offered in CTC\",\"Pecent_hike_expected_in_CTC\") \\\n",
    "        .withColumnRenamed(\"Percent difference CTC\",\"Percent_difference_CTC\") \\\n",
    "        .withColumnRenamed(\"Joining Bonus\",\"Joining_Bonus\")\\\n",
    "        .withColumnRenamed(\"Candidate relocate actual\",\"Candidate_relocate_actual\")\\\n",
    "        .withColumnRenamed(\"Candidate Source\",\"Candidate_Source\")\\\n",
    "        .withColumnRenamed(\"Rex in Yrs\",\"Rex_in_Yrs\")\\\n",
    ".withColumnRenamed(\"LOB_id\",\"LOB_id\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Candidate_Ref: integer (nullable = true)\n",
      " |-- DOJ_Extended: string (nullable = true)\n",
      " |-- Duration_to_accept_offer: integer (nullable = true)\n",
      " |-- Notice_period: integer (nullable = true)\n",
      " |-- Offered_band: string (nullable = true)\n",
      " |-- Percent_hike_offered_in_CTC: double (nullable = true)\n",
      " |-- Pecent_hike_expected_in_CTC: double (nullable = true)\n",
      " |-- Percent_difference_CTC: double (nullable = true)\n",
      " |-- Joining_Bonus: string (nullable = true)\n",
      " |-- Candidate_relocate_actual: string (nullable = true)\n",
      " |-- Gender: string (nullable = true)\n",
      " |-- Candidate_Source: string (nullable = true)\n",
      " |-- Rex_in_Yrs: integer (nullable = true)\n",
      " |-- Location: string (nullable = true)\n",
      " |-- Age: integer (nullable = true)\n",
      " |-- LOB_id: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "hr_hiring.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF2=spark.read.load('/home/hduser/Downloads/sharedfolder/Employee_joining_status.csv', format='csv', sep=',',inferSchema='true',header='true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Candidate Ref: integer (nullable = true)\n",
      " |-- Status: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "DF2.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "joining_status = DF2.withColumnRenamed(\"Candidate Ref\",\"Candidate_Ref\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Candidate_Ref: integer (nullable = true)\n",
      " |-- Status: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "joining_status.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "lob_mapping=spark.read.load('/home/hduser/Downloads/sharedfolder/LOB_mapping_P4.csv', format='csv', sep=',',inferSchema='true',header='true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- LOB_id: integer (nullable = true)\n",
      " |-- LOB: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lob_mapping.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Executing Hive Queries in Pyspark.   \n",
    "Creation of new database : capstone4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"CREATE DATABASE IF NOT EXISTS capstone4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the data into the respective tables from the pyspark dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "hr_hiring.coalesce(1).write.saveAsTable(\"capstone4.hr_hiring_details\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "joining_status.coalesce(1).write.saveAsTable(\"capstone4.employee_joining_status\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "lob_mapping.coalesce(1).write.saveAsTable(\"capstone4.lob_mapping_p4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Three tables are created:  \n",
    "    1) hr_hiring_details     \n",
    "    2) employee_joining_status   \n",
    "    3) lob_mapping_p4  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql('use capstone4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------------+-----------+\n",
      "| database|           tableName|isTemporary|\n",
      "+---------+--------------------+-----------+\n",
      "|capstone4|employee_joining_...|      false|\n",
      "|capstone4|   hr_hiring_details|      false|\n",
      "|capstone4|hr_hiring_details...|      false|\n",
      "|capstone4|      lob_mapping_p4|      false|\n",
      "+---------+--------------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('show tables').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform profiling of the data through PySpark and ensure that it is migrated correctly whereever the source is an RDBMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+------------+------------------------+-------------+------------+---------------------------+---------------------------+----------------------+-------------+-------------------------+------+-----------------+----------+--------+---+------+\n",
      "|Candidate_Ref|DOJ_Extended|Duration_to_accept_offer|Notice_period|Offered_band|Percent_hike_offered_in_CTC|Pecent_hike_expected_in_CTC|Percent_difference_CTC|Joining_Bonus|Candidate_relocate_actual|Gender| Candidate_Source|Rex_in_Yrs|Location|Age|LOB_id|\n",
      "+-------------+------------+------------------------+-------------+------------+---------------------------+---------------------------+----------------------+-------------+-------------------------+------+-----------------+----------+--------+---+------+\n",
      "|      2110407|         Yes|                      14|           30|          E2|                     -20.79|                      13.16|                 42.86|           No|                       No|Female|           Agency|         7|   Noida| 34|     1|\n",
      "|      2112635|          No|                      18|           30|          E2|                       50.0|                      320.0|                 180.0|           No|                       No|  Male|Employee Referral|         8| Chennai| 34|     2|\n",
      "|      2112838|          No|                       3|           45|          E2|                      42.84|                      42.84|                   0.0|           No|                       No|  Male|           Agency|         4|   Noida| 27|     2|\n",
      "|      2115021|          No|                      26|           30|          E2|                      42.84|                      42.84|                   0.0|           No|                       No|  Male|Employee Referral|         4|   Noida| 34|     2|\n",
      "|      2115125|         Yes|                       1|          120|          E2|                      42.59|                      42.59|                   0.0|           No|                      Yes|  Male|Employee Referral|         6|   Noida| 34|     2|\n",
      "|      2117167|         Yes|                      17|           30|          E1|                      42.83|                      42.83|                   0.0|           No|                       No|  Male|Employee Referral|         2|   Noida| 34|     2|\n",
      "|      2119124|         Yes|                      37|           30|          E2|                      31.58|                      31.58|                   0.0|           No|                       No|  Male|Employee Referral|         7|   Noida| 32|     2|\n",
      "|      2127572|         Yes|                      16|            0|          E1|                      -20.0|                      -20.0|                   0.0|           No|                       No|Female|           Direct|         8|   Noida| 34|     3|\n",
      "|      2138169|          No|                       1|           30|          E1|                     -22.22|                     -22.22|                   0.0|           No|                       No|Female|Employee Referral|         3| Gurgaon| 26|     4|\n",
      "|      2143362|          No|                       6|           30|          E1|                      240.0|                      220.0|                 -5.88|           No|                       No|  Male|Employee Referral|         3| Chennai| 34|     5|\n",
      "+-------------+------------+------------------------+-------------+------------+---------------------------+---------------------------+----------------------+-------------+-------------------------+------+-----------------+----------+--------+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('select * from hr_hiring_details limit 10').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+------+\n",
      "|Candidate_Ref|Status|\n",
      "+-------------+------+\n",
      "|      2110407|Joined|\n",
      "|      2112635|Joined|\n",
      "|      2112838|Joined|\n",
      "|      2115021|Joined|\n",
      "|      2115125|Joined|\n",
      "|      2117167|Joined|\n",
      "|      2119124|Joined|\n",
      "|      2127572|Joined|\n",
      "|      2138169|Joined|\n",
      "|      2143362|Joined|\n",
      "+-------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('select * from employee_joining_status limit 10').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+\n",
      "|LOB_id|       LOB|\n",
      "+------+----------+\n",
      "|     1|       ERS|\n",
      "|     2|     INFRA|\n",
      "|     3|Healthcare|\n",
      "|     4|      BFSI|\n",
      "|     5|      CSMP|\n",
      "|     6|       ETS|\n",
      "|     7|      AXON|\n",
      "|     8|       EAS|\n",
      "|     9|       MMS|\n",
      "+------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('select * from lob_mapping_p4 limit 10').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+-------+\n",
      "|            col_name|data_type|comment|\n",
      "+--------------------+---------+-------+\n",
      "|       Candidate_Ref|      int|   null|\n",
      "|        DOJ_Extended|   string|   null|\n",
      "|Duration_to_accep...|      int|   null|\n",
      "|       Notice_period|      int|   null|\n",
      "|        Offered_band|   string|   null|\n",
      "|Percent_hike_offe...|   double|   null|\n",
      "|Pecent_hike_expec...|   double|   null|\n",
      "|Percent_differenc...|   double|   null|\n",
      "|       Joining_Bonus|   string|   null|\n",
      "|Candidate_relocat...|   string|   null|\n",
      "|              Gender|   string|   null|\n",
      "|    Candidate_Source|   string|   null|\n",
      "|          Rex_in_Yrs|      int|   null|\n",
      "|            Location|   string|   null|\n",
      "|                 Age|      int|   null|\n",
      "|              LOB_id|      int|   null|\n",
      "+--------------------+---------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('desc hr_hiring_details').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+---------+-------+\n",
      "|     col_name|data_type|comment|\n",
      "+-------------+---------+-------+\n",
      "|Candidate_Ref|      int|   null|\n",
      "|       Status|   string|   null|\n",
      "+-------------+---------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('desc employee_joining_status').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------+-------+\n",
      "|col_name|data_type|comment|\n",
      "+--------+---------+-------+\n",
      "|  LOB_id|      int|   null|\n",
      "|     LOB|   string|   null|\n",
      "+--------+---------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('desc lob_mapping_p4').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spark Dataframes' describe method is used for summary statistics. The summary statistics includes min, max, count, mean and standard deviations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+------------+------------------------+------------------+------------+---------------------------+---------------------------+----------------------+-------------+-------------------------+------+-----------------+------------------+---------+------------------+------------------+\n",
      "|summary|    Candidate_Ref|DOJ_Extended|Duration_to_accept_offer|     Notice_period|Offered_band|Pecent_hike_expected_in_CTC|Percent_hike_offered_in_CTC|Percent_difference_CTC|Joining_Bonus|Candidate_relocate_actual|Gender| Candidate_Source|        Rex_in_Yrs| Location|               Age|            LOB_id|\n",
      "+-------+-----------------+------------+------------------------+------------------+------------+---------------------------+---------------------------+----------------------+-------------+-------------------------+------+-----------------+------------------+---------+------------------+------------------+\n",
      "|  count|             8995|        8995|                    8995|              8995|        8982|                       8995|                       8995|                  8995|         8995|                     8995|  8995|             8995|              8995|     8995|              8980|              8995|\n",
      "|   mean|2843647.377765425|        null|      21.434463590883823| 39.29182879377432|        null|          40.65735630906044|          43.86480377987742|   -1.5738021122846075|         null|                     null|  null|             null| 4.239021678710395|     null|29.912026726057906|3.1130628126737077|\n",
      "| stddev|486344.7745519215|        null|      25.811615717050906|22.220239481838103|        null|          36.06405981089342|          29.78897499097193|    19.610728841580432|         null|                     null|  null|             null|2.5475706093546893|     null|4.0956992472101605|2.1259019490845583|\n",
      "|    min|          2109586|          No|                       0|                 0|          E0|                     -60.53|                     -68.83|                -67.27|           No|                       No|Female|           Agency|                 0|Ahmedabad|                20|                 1|\n",
      "|    max|          3836076|         Yes|                     224|               120|          E3|                     471.43|                     359.77|                 300.0|          Yes|                      Yes|  Male|Employee Referral|                24|     Pune|                60|                 9|\n",
      "+-------+-----------------+------------+------------------------+------------------+------------+---------------------------+---------------------------+----------------------+-------------+-------------------------+------+-----------------+------------------+---------+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Checking Statistics\n",
    "resultdf=hr_hiring.describe('Candidate_Ref','DOJ_Extended','Duration_to_accept_offer','Notice_period','Offered_band','Pecent_hike_expected_in_CTC','Percent_hike_offered_in_CTC','Percent_difference_CTC','Joining_Bonus','Candidate_relocate_actual','Gender','Candidate_Source','Rex_in_Yrs','Location','Age','LOB_id')\n",
    "resultdf.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking the null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+------------+------------------------+-------------+------------+---------------------------+---------------------------+----------------------+-------------+-------------------------+------+----------------+----------+--------+---+------+\n",
      "|Candidate_Ref|DOJ_Extended|Duration_to_accept_offer|Notice_period|Offered_band|Percent_hike_offered_in_CTC|Pecent_hike_expected_in_CTC|Percent_difference_CTC|Joining_Bonus|Candidate_relocate_actual|Gender|Candidate_Source|Rex_in_Yrs|Location|Age|LOB_id|\n",
      "+-------------+------------+------------------------+-------------+------------+---------------------------+---------------------------+----------------------+-------------+-------------------------+------+----------------+----------+--------+---+------+\n",
      "|            0|           0|                       0|            0|          13|                          0|                          0|                     0|            0|                        0|     0|               0|         0|       0| 15|     0|\n",
      "+-------------+------------+------------------------+-------------+------------+---------------------------+---------------------------+----------------------+-------------+-------------------------+------+----------------+----------+--------+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col,isnan, when, count\n",
    "hr_hiring.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in hr_hiring.columns]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking the median for the column Age."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.approxQuantile(\"Age\",[0.5],0.25)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Treating the null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=hr_hiring.na.fill({'Offered_band':'E1'}) #Filling null values for offered Band with E1(Mode)\n",
    "df1=df1.na.fill({'Age':27}) #Filling null values for Age with the median i.e. 27"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+------------+------------------------+-------------+------------+---------------------------+---------------------------+----------------------+-------------+-------------------------+------+----------------+----------+--------+---+------+\n",
      "|Candidate_Ref|DOJ_Extended|Duration_to_accept_offer|Notice_period|Offered_band|Percent_hike_offered_in_CTC|Pecent_hike_expected_in_CTC|Percent_difference_CTC|Joining_Bonus|Candidate_relocate_actual|Gender|Candidate_Source|Rex_in_Yrs|Location|Age|LOB_id|\n",
      "+-------------+------------+------------------------+-------------+------------+---------------------------+---------------------------+----------------------+-------------+-------------------------+------+----------------+----------+--------+---+------+\n",
      "|            0|           0|                       0|            0|           0|                          0|                          0|                     0|            0|                        0|     0|               0|         0|       0|  0|     0|\n",
      "+-------------+------------+------------------------+-------------+------------+---------------------------+---------------------------+----------------------+-------------+-------------------------+------+----------------+----------+--------+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Checking the Null values\n",
    "df1.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in df1.columns]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+------+\n",
      "|Candidate_Ref|Status|\n",
      "+-------------+------+\n",
      "|            0|     0|\n",
      "+-------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col,isnan, when, count\n",
    "joining_status.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in joining_status.columns]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+\n",
      "|LOB_id|LOB|\n",
      "+------+---+\n",
      "|     0|  0|\n",
      "+------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col,isnan, when, count\n",
    "lob_mapping.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in lob_mapping.columns]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No null values are observed in the given datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.coalesce(1).write.saveAsTable(\"capstone4.hr_hiring_details_final\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------+\n",
      "|    status|count(status)|\n",
      "+----------+-------------+\n",
      "|Not Joined|         1682|\n",
      "|    Joined|         7313|\n",
      "+----------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query1=spark.sql(\"select status,count(status) from employee_joining_status group by status\")\n",
    "query1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
